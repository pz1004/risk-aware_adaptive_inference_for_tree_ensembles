%Version 3.1 December 2024
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%=========================================================================================%%
%% the documentclass is set to pdflatex as default. You can delete it if not appropriate.  %%
%%=========================================================================================%%

%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-chicago.bst%  
 
%%\documentclass[pdflatex,sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style
%%\documentclass[pdflatex,sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[pdflatex,sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[pdflatex,sn-vancouver-num]{sn-jnl}% Vancouver Numbered Reference Style
%%\documentclass[pdflatex,sn-vancouver-ay]{sn-jnl}% Vancouver Author Year Reference Style
%%\documentclass[pdflatex,sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[pdflatex,sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\hypersetup{bookmarksdepth=3}
%%%%


%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Risk-Aware Adaptive Inference]{Risk-Aware Adaptive Inference: Calibrated and Closed-Loop Early Exiting for Tree Ensembles under Distribution Shift}

\author[1]{\fnm{Sooyoung} \sur{Jang}}\email{syjang@hanbat.ac.kr}

\author*[1]{\fnm{Changbeom} \sur{Choi}}\email{cbchoi@hanbat.ac.kr}

\affil[1]{\orgdiv{Department of Computer Engineering}, \orgname{Hanbat National University}, \orgaddress{\city{Daejeon}, \postcode{34158}, \country{Republic of Korea}}}


\abstract{Tree ensembles are widely deployed for tabular prediction, but their inference cost grows linearly with the number of trees or boosting stages, which can violate latency and throughput budgets in production systems. Adaptive inference (early exiting) reduces expected evaluation work by stopping on ``easy'' inputs, yet common confidence heuristics are often miscalibrated and can fail under distribution shift, causing premature exits with elevated error among exited samples. We propose \emph{Risk-Aware Adaptive Inference} (RAAI), a deployment-oriented framework that replaces heuristic stopping with a calibrated \emph{flip-risk} signal: the probability that a prefix (partial-ensemble) prediction would disagree with the full-ensemble prediction. RAAI then applies a closed-loop, OOD-aware stopping policy that tightens admissible flip-risk and can disable early exit for distributionally suspicious inputs, mitigating the principal failure mode of early exit under shift. Across MNIST, Covertype, and HIGGS with Random Forest and Gradient Boosting ensembles ($T{=}100$), RAAI achieves substantial in-distribution work reduction (63--84\% fewer evaluated components on average) while maintaining low disagreement with the full ensemble, and it reduces early-exit failure rates on near- and far-OOD shifts relative to heuristic early-exit baselines. Importantly, we distinguish algorithmic \emph{work reduction} (fewer evaluated trees) from \emph{wall-clock runtime}: in our current Python prototype, RAAI demonstrates controllable work reduction and improved shift robustness, while end-to-end acceleration depends on low-overhead integration of the stopping logic and OOD scoring, which we analyze explicitly.
}

\keywords{Adaptive Inference, Tree Ensembles, Out-of-Distribution Detection, Calibration, Risk-Aware Learning}

\maketitle

\section{Introduction}
\label{sec:intro}

Tree ensembles, such as Random Forests (RF) and Gradient Boosting Machines (GBM), remain the dominant approach for tabular data tasks due to their robust performance and interpretability. However, their inference cost scales linearly with the number of trees, which can be prohibitive for latency-sensitive applications. Adaptive inference, or early exiting, addresses this by halting evaluation once a prediction is sufficiently stable. While effective on in-distribution (ID) data, standard stopping rules often rely on uncalibrated heuristics (e.g., confidence thresholds) that fail under distribution shift. A critical failure mode is \textit{overconfident early exiting}, where OOD inputs trigger premature stops on erroneous predictions, bypassing the robustness of the full ensemble.

In this work, we present Risk-Aware Adaptive Inference (RAAI) for tree ensembles, motivated by practical tabular deployments where average compute must be reduced without sacrificing reliability when inputs deviate from training conditions. RAAI replaces confidence-threshold stopping with a calibrated estimate of \emph{flip risk}---the probability that a prefix prediction would disagree with the full-ensemble prediction---and uses this probability as an interpretable operating knob for early exit. To address the brittleness of confidence heuristics under distribution shift, we further introduce a closed-loop controller that conditions the stopping tolerance and minimum evaluated prefix on a lightweight OOD suspicion score, conservatively allocating additional computation to ambiguous or novel inputs and escalating to full evaluation when warranted. Our evaluation emphasizes deployment-facing, measurable outcomes: in-distribution work reduction (WR) and fidelity to the full model (disagreement rate), together with OOD safety metrics that quantify early-exit failures under near- and far-shift regimes. We also report a runtime analysis that separates work saved from time saved, showing that while RAAI reduces evaluated components substantially, the current Python implementation introduces overhead; thus, practical wall-clock gains require optimized integration of the controller and the OOD query.

Our contributions are as follows:
\begin{itemize}
    \item \textbf{Deployment-facing risk control for early exit in tree ensembles.}
    We formulate adaptive inference as selecting a stopping time that limits the probability of \emph{disagreement with the full ensemble} (flip risk), yielding a practitioner-interpretable fidelity constraint that can be validated on held-out in-distribution traffic.
    \item \textbf{Calibrated flip-risk estimation from prefix-state signals.}
    We learn a lightweight calibrator over low-dimensional prefix features (e.g., vote/logit margins and progress $t/T$) to estimate $\hat{p}_{\mathrm{agree}}(t,x)=\mathbb{P}(\hat{y}_t(x)=\hat{y}_T(x))$, enabling probabilistic stopping decisions rather than heuristic confidence thresholds.
    \item \textbf{Closed-loop, shift-aware stopping with OOD-gated escalation.}
    We integrate an OOD suspicion score into the inference loop to tighten the admissible flip risk and increase minimum prefix length for suspicious inputs, with a hard gate that can disable early exit under strong novelty, reducing overconfident premature exits under distribution shift.
    \item \textbf{Evaluation with measurable deployment outcomes under shift.}
    On MNIST, Covertype, and HIGGS with RF/GBM ensembles, we report WR/DR/EER operating outcomes on in-distribution data and on near- and far-OOD shifts, together with calibration diagnostics (reliability diagrams, ECE/MCE) and OOD-score utility (AUROC) relevant to gating.
    \item \textbf{Practical impact clarification via work--runtime separation.}
    We quantify both achieved work reduction and end-to-end runtime behavior, explicitly distinguishing reduced evaluated components from realized wall-clock performance and identifying the overhead sources that must be optimized for production deployments.
\end{itemize}

\section{Related Work}
\label{sec:related}

\subsection{Adaptive inference for tree ensembles}
Tree ensembles (e.g., Random Forests and Gradient Boosting Machines) are widely deployed for tabular prediction, but their inference cost scales with the number of trees (or boosting stages). A substantial body of work targets \emph{full-evaluation} acceleration for additive tree ensembles via algorithmic and systems techniques such as cache- and SIMD-friendly layouts, compact representations, and data-level parallelization. Representative examples include QuickScorer, which uses bitvector-based techniques to accelerate scoring for ensembles of regression trees in ranking, and RapidScorer, which emphasizes compactness and SIMD-driven parallel evaluation for high-throughput tree ensemble inference \cite{lucchese2015quickscorer,ye2018rapidscorer}. These approaches aim to reduce the constant factors of evaluating the entire ensemble, and are complementary to methods that reduce the \emph{expected number of evaluated components}.

Adaptive (variable-compute) inference has been extensively studied in deep models via \emph{early-exit} architectures and anytime prediction, where examples may exit after partial computation if a confidence criterion is met. BranchyNet introduces early-exit branches to reduce average inference time, while MSDNet proposes multi-scale dense connections to support resource-efficient anytime classification \cite{teerapittayanon2016branchynet,huang2018msdnet}. Translating early-exit principles to tree ensembles is non-trivial: the relevant control signals differ (e.g., vote/logit stabilization under partial evaluation), and tabular deployments often impose strict latency SLOs, deterministic execution constraints, and a preference for minimal inference-time overhead. Accordingly, adaptive inference for ensembles in practical settings requires stopping rules that are both \emph{interpretable} and \emph{robust} to distribution shift.

\subsection{Selective prediction, risk control, and calibration}
Selective prediction (reject option) provides a principled framework for improving reliability by trading coverage for reduced risk. Classical results study the optimal trade-off between error and rejection under an explicit reject cost \cite{chow1970reject}. Modern selective classification extends this view to learned selection functions and risk--coverage analysis, including formulations for deep models \cite{geifman2017selective} and integrated architectures such as SelectiveNet \cite{geifman2019selectivenet}. In parallel, conformal prediction provides model-agnostic procedures for constructing prediction sets with marginal coverage guarantees under exchangeability, and is increasingly used as a reliability layer in deployed inference pipelines \cite{shafer2008conformal}.

Across selective prediction and conformal approaches, \emph{calibration} is a central prerequisite: thresholds and risk controls are only meaningful when confidence scores correspond to empirical frequencies. Canonical post-hoc calibration methods include Platt scaling \cite{platt1999probabilistic}, multiclass probability calibration \cite{zadrozny2002transforming}, and nonparametric corrections such as isotonic regression; systematic empirical analyses document how calibration varies across model families \cite{niculescu2005predicting}. In modern practice, calibration error metrics (e.g., ECE) and reliability diagrams are standard diagnostics \cite{guo2017calibration}. 

The present work is related in spirit to selective prediction and calibration, but differs in \emph{what is being calibrated and controlled}. Rather than controlling prediction error risk or coverage, we calibrate and threshold a \emph{flip-risk} quantity: the probability that a partial-ensemble prediction disagrees with the full-ensemble prediction. This yields a deployment-relevant control objective---fidelity to the full model---that supports early exiting without requiring abstention, while remaining compatible with operational constraints where the full model is a trusted reference.

\subsection{OOD detection integrated into inference}
Reliability in deployment is often limited by distribution shift, motivating out-of-distribution (OOD) detection as a safety mechanism. Standard baselines include confidence-based detectors such as maximum softmax probability \cite{hendrycks2017baseline}, as well as enhanced procedures that modify scores or inputs (e.g., ODIN) \cite{liang2017odin}. Additional families of methods use feature-space distance or density proxies, including Mahalanobis-based detectors \cite{lee2018mahalanobis} and energy-based scores \cite{liu2020energy}. Recent surveys emphasize that practical OOD detection performance depends strongly on the shift regime (near-OOD vs.\ far-OOD), modality, and deployment context \cite{yang2024oodsurvey}.

For tabular systems, lightweight novelty and outlier detectors are frequently adopted because they are model-agnostic and computationally simple. Examples include Local Outlier Factor (LOF) \cite{breunig2000lof} and Isolation Forest \cite{liu2008iforest}, which can serve as pre-filters, monitors, or auxiliary signals. In many deployments, however, OOD detection is treated as \emph{separate} from the main inference procedure, triggering rejection, escalation, or fallback rather than modulating how much computation is spent by the predictor.

Our approach integrates OOD suspicion directly into the inference loop: an OOD signal modulates the admissible flip-risk used for early exiting, conservatively allocating more computation to potentially shifted inputs while preserving aggressive early exits on in-distribution-like samples. This integration targets a common failure mode in adaptive inference---overconfident premature exits under shift---without asserting that OOD detection alone is sufficient for robustness.

\paragraph{Gap and positioning.}
Existing work provides strong tools for (i) accelerating full evaluation of tree ensembles \cite{lucchese2015quickscorer,ye2018rapidscorer}, (ii) controlling reliability via selective prediction and calibrated uncertainty \cite{chow1970reject,geifman2019selectivenet,shafer2008conformal}, and (iii) detecting distribution shift and novelty \cite{hendrycks2017baseline,liang2017odin,lee2018mahalanobis,liu2020energy,yang2024oodsurvey}. What is comparatively less developed for deployed tabular inference is an \emph{integrated} early-exit mechanism that uses a calibrated estimate of \emph{disagreement risk with the full ensemble} as the stopping criterion, and that \emph{adapts} this criterion under suspected shift using an OOD signal. The proposed RAAI framework is positioned at this intersection: it combines calibrated flip-risk control with OOD-gated stopping to reduce evaluation work on in-distribution data while mitigating early-exit brittleness under distribution shift.


\section{Risk-Aware Adaptive Inference}\label{sec:method}

We propose \emph{Risk-Aware Adaptive Inference} (RAAI), a framework for early-exit inference in
tree ensembles that explicitly targets reliability under distribution shift. RAAI combines
(i) a calibrated estimator of \emph{flip risk}---the probability that a prefix prediction will disagree
with the full ensemble---and (ii) a closed-loop stopping policy that modulates the admissible risk
based on an out-of-distribution (OOD) suspicion score.

\subsection{Problem formulation}\label{subsec:problem}
Consider an ensemble model $F$ consisting of $T$ sequential components
(e.g., trees in a Random Forest or boosting stages in a GBM), denoted
$F=\{f_1,\ldots,f_T\}$. For an input $x$, let $\hat{y}_t(x)$ denote the \emph{prefix prediction}
using only the first $t$ components, and let $\hat{y}_T(x)$ denote the full-model prediction.
Adaptive inference seeks a stopping time $t^*(x)\in\{1,\ldots,T\}$ that reduces computation
while maintaining high fidelity to the full model. We formalize fidelity via a disagreement-risk
constraint:
\begin{equation}
\mathbb{P}\!\left(\hat{y}_{t^*}(x)\neq \hat{y}_T(x)\right)\le \delta,
\label{eq:fliprisk_constraint}
\end{equation}
where $\delta\in[0,1]$ is a user-defined tolerance for disagreement. In contrast to heuristic confidence thresholds, RAAI explicitly estimates and controls this disagreement probability. The constraint in Eq.~\ref{eq:fliprisk_constraint} controls \emph{fidelity to the full ensemble}, not prediction correctness with respect to ground-truth labels. This distinction is intentional and deployment-oriented: in many production settings, the full ensemble is the validated reference decision rule, and the operational requirement is that adaptive inference should deviate from that reference only with a user-specified small probability. Consequently, our primary risk signal is a calibrated estimate of $\Pr(\hat{y}_t(x)\neq \hat{y}_T(x))$ (flip risk), and our main evaluation metrics emphasize Work Reduction (WR) and Disagreement Rate (DR) with respect to $\hat{y}_T(x)$. We additionally report ID accuracy to confirm that high fidelity to the full model preserves task performance on in-distribution data.

\subsection{Calibrated flip-risk estimation}\label{subsec:calibration}
Instead of raw confidence or margin heuristics, RAAI models the probability that the current
prefix prediction is already consistent with full inference. Define the \emph{agreement probability}
at step $t$:
\begin{equation}
p_{\mathrm{agree}}(t,x)
=\mathbb{P}\!\left(\hat{y}_t(x)=\hat{y}_T(x)\mid \phi_t(x)\right),
\label{eq:agree_prob}
\end{equation}
where $\phi_t(x)$ is a lightweight feature vector summarizing the inference state at step $t$.
We then estimate $\hat{p}_{\mathrm{agree}}(t,x)$ with a calibrated model.

\paragraph{Prefix-state features.}
We construct $\phi_t(x)$ from quantities available during prefix evaluation.
For Random Forests (RF), we use the vote margin (top-1 minus top-2 vote counts), normalized
confidence, and normalized depth $t/T$.
For Gradient Boosting Machines (GBM), we use the logit margin, softmax confidence, and $t/T$.
These features are designed to be low-dimensional and inexpensive to compute.

\paragraph{Calibration model.}
We train a calibrator $C(\cdot)$ on a held-out in-distribution calibration set $D_{\mathrm{cal}}$.
For each $(x,y)\in D_{\mathrm{cal}}$, we compute the full prediction $\hat{y}_T(x)$ and (optionally)
a set of prefix predictions $\hat{y}_t(x)$ for $t\in\{1,\ldots,T\}$ (or a sparse grid of $t$ values).
We then form supervised pairs
\[
\big(\phi_t(x),\; z_t(x)\big),\quad
z_t(x)=\mathbb{I}\!\left[\hat{y}_t(x)=\hat{y}_T(x)\right],
\]
and fit a logistic regression calibrator $C$ to estimate
$\hat{p}_{\mathrm{agree}}(t,x)=C\!\left(\phi_t(x)\right)$.
Because $\hat{p}_{\mathrm{agree}}(t,x)$ is calibrated on $D_{\mathrm{cal}}$, it is directly interpretable
as a probability of agreement, enabling risk-threshold selection in the stopping rule.

\subsection{OOD-aware closed-loop stopping}\label{subsec:ood}
Confidence-based early exit can be brittle under distribution shift: the model may appear confident
early in evaluation on OOD inputs. To mitigate this failure mode, we introduce an OOD suspicion score
$u(x)$ and use it to adapt the admissible disagreement risk as well as the minimum prefix length.

\paragraph{Suspicion score via KNN distance.}
We compute $u(x)$ using the (normalized) distance from $x$ to its $k$ nearest neighbors in an
in-distribution reference set (e.g., the training set or a subsample). Let $d_k(x)$ denote the average
(or maximum) distance to the $k$ nearest neighbors returned by a KNN index. We then define a normalized
suspicion score
\[
u(x)=\mathrm{Norm}(d_k(x)),
\]
where $\mathrm{Norm}(\cdot)$ is any fixed normalization computed on ID reference data (e.g., z-score or
min--max scaling over $D_{\mathrm{cal}}$). Larger $u(x)$ indicates that $x$ is further from the ID manifold
and therefore more likely to be distributionally novel.

\paragraph{Adaptive stopping rule.}
RAAI stops at step $t$ when the calibrated agreement probability exceeds a risk-adjusted threshold and
the prefix is sufficiently long:
\begin{equation}
\hat{p}_{\mathrm{agree}}(t,x)\ \ge\ 1-\delta(u(x))
\quad \text{and} \quad
t\ \ge\ t_{\min}(u(x)).
\label{eq:stopping_rule}
\end{equation}
Here, $\hat{p}_{\mathrm{agree}}(t,x)$ is the calibrated estimate of
$\Pr(\hat{y}_t(x)=\hat{y}_T(x)\mid \phi_t(x))$ (Eq.~(2)), and $\delta(\cdot)$ and $t_{\min}(\cdot)$ are
policies that tighten reliability requirements for suspicious inputs.

\paragraph{Two-level suspicious policy with hard gate.}
We employ a two-level policy that distinguishes \emph{non-suspicious} and \emph{suspicious} inputs, with
an additional \emph{hard gate} that forces full inference when the input is highly suspicious. Concretely,
\begin{equation}
\delta(u(x))=
\begin{cases}
\delta_{\mathrm{ID}}, & u(x)\le \tau_{\mathrm{susp}},\\
\delta_{\mathrm{susp}}, & \tau_{\mathrm{susp}} < u(x)\le \tau_{\mathrm{gate}},\\
0, & u(x)>\tau_{\mathrm{gate}},
\end{cases}
\label{eq:delta_policy}
\end{equation}
where $\tau_{\mathrm{susp}}$ switches the risk tolerance from $\delta_{\mathrm{ID}}$ to the more conservative
$\delta_{\mathrm{susp}}$, and $\tau_{\mathrm{gate}}$ disables early exit by forcing full inference when
$u(x)>\tau_{\mathrm{gate}}$ (yielding $t^*(x)=T$).

We analogously use a suspicion-aware minimum prefix length:
\begin{equation}
t_{\min}(u(x))=
\begin{cases}
t^{\mathrm{ID}}_{\min}, & u(x)\le \tau_{\mathrm{susp}},\\
t^{\mathrm{susp}}_{\min}, & \tau_{\mathrm{susp}} < u(x)\le \tau_{\mathrm{gate}},\\
T, & u(x)>\tau_{\mathrm{gate}}.
\end{cases}
\label{eq:tmin_policy}
\end{equation}
This prevents overly early exits on suspicious samples by requiring a longer prefix before the stopping
condition in Eq.~\eqref{eq:stopping_rule} is evaluated.

\subsection{RAAI inference algorithm}\label{subsec:algorithm}
Algorithm~\ref{alg:raai} provides an implementation-ready inference procedure for the two-level suspicious
policy (Eqs.~\eqref{eq:stopping_rule}--\eqref{eq:tmin_policy}). The algorithm returns both the prediction
and the realized stopping time.

\begin{algorithm}[t]
\caption{Risk-Aware Adaptive Inference (RAAI) with two-level suspicious policy and hard gate}
\label{alg:raai}
\begin{algorithmic}[1]
\Require Ensemble $F=\{f_1,\ldots,f_T\}$; input $x$; calibrator $C$; KNN index $\mathcal{I}$;
parameters $\delta_{\mathrm{ID}}, \delta_{\mathrm{susp}}, \tau_{\mathrm{susp}}, \tau_{\mathrm{gate}},
t^{\mathrm{ID}}_{\min}, t^{\mathrm{susp}}_{\min}, k$
\Ensure Prediction $\hat{y}$ and stopping time $t^*$

\State $u \gets \Call{NormalizedKNNDistance}{\mathcal{I}, x, k}$ \Comment{OOD suspicion score $u(x)$}
\If{$u > \tau_{\mathrm{gate}}$} \Comment{hard gate: force full inference}
    \State $\hat{y} \gets \Call{FullPredict}{F, x}$ \Comment{$\hat{y}_T(x)$}
    \State \Return $(\hat{y}, T)$
\ElsIf{$u > \tau_{\mathrm{susp}}$} \Comment{suspicious regime}
    \State $\delta \gets \delta_{\mathrm{susp}}$
    \State $t_{\min} \gets t^{\mathrm{susp}}_{\min}$
\Else \Comment{non-suspicious (ID-like) regime}
    \State $\delta \gets \delta_{\mathrm{ID}}$
    \State $t_{\min} \gets t^{\mathrm{ID}}_{\min}$
\EndIf

\State $s \gets \Call{InitState}{}$ \Comment{aggregation state (votes/logits) for prefix evaluation}
\For{$t=1$ \textbf{to} $T$}
    \State $s \gets \Call{UpdateState}{s, f_t, x}$ \Comment{evaluate component $f_t$ and update state}
    \If{$t < t_{\min}$}
        \State \textbf{continue}
    \EndIf
    \State $\hat{y}_t \gets \Call{PredictFromState}{s}$ \Comment{prefix prediction $\hat{y}_t(x)$}
    \State $\phi \gets \Call{ExtractPrefixFeatures}{s, t, T}$ \Comment{feature vector $\phi_t(x)$}
    \State $\hat{p} \gets \Call{C}{\phi}$ \Comment{$\hat{p}_{\mathrm{agree}}(t,x)$ (Eq.~(2))}
    \If{$\hat{p} \ge 1-\delta$} \Comment{Eq.~\eqref{eq:stopping_rule} with Eqs.~\eqref{eq:delta_policy}--\eqref{eq:tmin_policy}}
        \State \Return $(\hat{y}_t, t)$
    \EndIf
\EndFor

\State $\hat{y} \gets \Call{PredictFromState}{s}$ \Comment{after loop, equals $\hat{y}_T(x)$}
\State \Return $(\hat{y}, T)$
\end{algorithmic}
\end{algorithm}

\subsection{Complexity analysis}\label{subsec:complexity}
Let $D$ denote the average per-component evaluation cost (e.g., average tree depth), and let $t^*(x)$
be the realized stopping time. Algorithm~\ref{alg:raai} has three principal runtime contributors per
sample: (i) one KNN query to compute $u(x)$, (ii) prefix evaluation of $t^*(x)$ components, and
(iii) feature extraction and calibrator evaluation after $t_{\min}(u(x))$.
Let $n$ be the size of the KNN reference set and $d_x$ be the feature dimension. With brute-force KNN,
the suspicion score computation costs $O(n\,d_x)$; with an index, the practical cost depends on the chosen
backend and may be sublinear in favorable regimes. Prefix evaluation costs $O(t^*(x)\,D)$.
Feature extraction and a logistic-regression calibrator evaluation cost $O(d_\phi)$ per checked step, where
$d_\phi=\dim(\phi_t)$ is a small constant; thus this overhead is
$O\!\left((t^*(x)-t_{\min}(u(x))+1)\,d_\phi\right)$.
Overall,
\[
\mathrm{Time}(x)=O\!\left(\mathrm{KNN}(n,d_x) + t^*(x)\,D + (t^*(x)-t_{\min}(u(x))+1)\,d_\phi\right),
\]
and memory is dominated by the ensemble parameters (total nodes across trees) plus the KNN reference store,
$O(n\,d_x)$ (ignoring indexing overhead), and the calibrator parameters, $O(d_\phi)$.
When $u(x)>\tau_{\mathrm{gate}}$, RAAI performs full inference ($t^*=T$) plus the KNN query; when
$u(x)\le\tau_{\mathrm{gate}}$, savings depend on how early the agreement threshold is met.

\subsection{Parameter setting and calibration split}\label{subsec:params}
RAAI exposes parameters that control the efficiency--reliability trade-off and conservativeness under
suspicion: $\delta_{\mathrm{ID}}$, $\delta_{\mathrm{susp}}$, $\tau_{\mathrm{susp}}$, $\tau_{\mathrm{gate}}$,
$t^{\mathrm{ID}}_{\min}$, $t^{\mathrm{susp}}_{\min}$, and the KNN parameter $k$. We provide practical
heuristics that require only ID data.

\paragraph{Calibration split $D_{\mathrm{cal}}$.}
Hold out $10$--$20\%$ of the ID training set as $D_{\mathrm{cal}}$ (stratified for classification). Train
the base ensemble $F$ on the remaining data, and train the calibrator $C$ on $D_{\mathrm{cal}}$ using
agreement labels $\mathbb{I}[\hat{y}_t(x)=\hat{y}_T(x)]$ across a range of prefix lengths $t$ (potentially on
a sparse grid to reduce preprocessing).

\paragraph{Minimum prefix lengths $t^{\mathrm{ID}}_{\min}$ and $t^{\mathrm{susp}}_{\min}$.}
Use $t^{\mathrm{ID}}_{\min}$ to avoid degenerate exits on ID-like samples, e.g.,
$t^{\mathrm{ID}}_{\min}=\max\{5,\lceil 0.05T\rceil\}$. Set $t^{\mathrm{susp}}_{\min}>t^{\mathrm{ID}}_{\min}$
to require more evidence before exiting on suspicious samples (e.g., $t^{\mathrm{susp}}_{\min}\in[0.2T,0.4T]$),
reflecting the higher risk of premature stabilization under shift.

\paragraph{ID risk tolerance $\delta_{\mathrm{ID}}$.}
Select $\delta_{\mathrm{ID}}$ using an ID validation split by sweeping
$\delta_{\mathrm{ID}}\in\{0.005,0.01,0.02,0.03,\allowbreak 0.05,0.10\}$ and choosing the largest value satisfying an
application-defined ID disagreement constraint (or matching a baseline's ID disagreement), thereby
maximizing work reduction subject to fidelity.

\paragraph{Suspicious risk tolerance $\delta_{\mathrm{susp}}$.}
Set $\delta_{\mathrm{susp}}<\delta_{\mathrm{ID}}$ to be more conservative on suspicious samples.
A robust heuristic is to set $\delta_{\mathrm{susp}}$ one order of magnitude smaller than $\delta_{\mathrm{ID}}$
(e.g., $\delta_{\mathrm{susp}}\in[\delta_{\mathrm{ID}}/10,\ \delta_{\mathrm{ID}}/2]$), and tune jointly with
$\tau_{\mathrm{susp}}$ and $\tau_{\mathrm{gate}}$ on ID validation by enforcing the same ID disagreement
constraint while checking that suspicious inputs reduce early-exit disagreement.

\paragraph{Suspicion thresholds $\tau_{\mathrm{susp}}$ and $\tau_{\mathrm{gate}}$.}
Compute $u(x)$ over ID calibration points and define $\tau_{\mathrm{gate}}$ as a high quantile (e.g.,
$Q_{0.95}$--$Q_{0.99}$) so only the most novel inputs force full inference. Set $\tau_{\mathrm{susp}}$ to a
lower quantile (e.g., $Q_{0.50}$--$Q_{0.80}$) so that a moderate fraction of inputs are treated as
``suspicious'' and evaluated with the conservative $(\delta_{\mathrm{susp}}, t^{\mathrm{susp}}_{\min})$ regime.
If representative shifted data are available, refine these quantiles to trade off ID work reduction versus
OOD disagreement without changing the policy form in Eqs.~\eqref{eq:delta_policy}--\eqref{eq:tmin_policy}.

\paragraph{KNN parameter $k$.}
In practice, small $k$ (e.g., $k\in[5,20]$) is sufficient for a stable suspicion score. Use $k=10$ as a
default and adjust only if $u(x)$ is overly noisy (increase $k$) or overly smooth (decrease $k$).


\section{Experimental Setup}
\label{sec:setup}

\subsection{Datasets, Preprocessing, and Shifts}
\label{subsec:datasets_preproc_shifts}
We evaluate on three benchmarks spanning image and tabular modalities: MNIST (image), Covertype (tabular),
and HIGGS (tabular). To keep experiments lightweight and consistent across runs, we subsample each dataset
per run to fixed sizes, as described below.

\paragraph{MNIST.}
We use the canonical MNIST digit classification task (10 classes). For each run, we subsample 20{,}000
training images from the standard 60{,}000-image training set and 5{,}000 in-distribution (ID) test
images from the standard 10{,}000-image test set.

\paragraph{Covertype.}
Covertype contains 54 features and 7 semantic classes. We construct an ID/OOD class split by treating
classes $\{1,2,3\}$ as ID (re-labeled to $\{0,1,2\}$) and holding out classes $\{4,5,6,7\}$ as Far-OOD.
For each run, we sample 20{,}000 ID training points, 5{,}000 ID test points, and 5{,}000 Far-OOD points
from the held-out classes.

\paragraph{HIGGS.}
HIGGS is a binary classification task with 28 real-valued features. For each run, we load the first
30{,}000 rows of the dataset, impute missing values using feature-wise medians, and then split into
20{,}000 training points and 5{,}000 ID test points (remaining rows are unused).

\paragraph{Tabular preprocessing.}
For tabular datasets (Covertype, HIGGS), we standardize features using a \texttt{StandardScaler} fit on
the 20{,}000-sample ID training pool and apply the same transform to the ID test and OOD evaluation sets.

\paragraph{Distribution shifts.}
We evaluate two deterministic shift regimes designed to probe a known failure mode of adaptive inference: \emph{overconfident premature exits} when early prefix signals no longer predict full-model agreement. \emph{Near-OOD} represents a mild covariate shift that preserves the task structure but perturbs inputs (MNIST: fixed $90^\circ$ rotation; tabular: additive Gaussian feature noise scaled by the ID training-pool standard deviation). \emph{Far-OOD} represents a more severe novelty regime (MNIST: fixed pixel permutation; HIGGS: independent feature-column permutations; Covertype: a semantic class hold-out). Because Far-OOD may not share the same label semantics as ID (e.g., held-out classes in Covertype), our primary shift-safety metrics are DR and the Early Exit Error Rate (EER) \emph{with respect to the full ensemble} rather than accuracy. These constructions are intended as controlled stress tests for early-exit reliability under shift; we discuss external-validity limitations and realistic drift scenarios in Section~\ref{subsec:discussion:limitations}.

\paragraph{Dataset access.}
All datasets are publicly available: MNIST (\url{https://yann.lecun.com/exdb/mnist/}),
Covertype (\url{https://archive.ics.uci.edu/ml/datasets/covertype}), and HIGGS
(\url{https://archive.ics.uci.edu/ml/datasets/HIGGS}).

\subsection{Splits, Seeds, and Number of Runs}
\label{subsec:splits_seeds_runs}
We report mean $\pm$ standard deviation over $R{=}10$ independent runs using seeds
$\{42,43,\dots,51\}$. For run seed $s$, dataset subsampling, shift construction, and all NumPy-based
randomness follow \texttt{np.random.seed(s)}.

Each run uses the following disjoint ID splits:
\begin{itemize}
    \item \textbf{Train pool} $\mathcal{D}_{\mathrm{train\_pool}}$ of size 20{,}000 (ID only).
    \item \textbf{Train} $\mathcal{D}_{\mathrm{train}}$ of size 15{,}000: used to fit the ensemble and the
    KNN-based suspicion model.
    \item \textbf{Validation/Calibration} $\mathcal{D}_{\mathrm{val}}{=}\mathcal{D}_{\mathrm{cal}}$ of size
    5{,}000: a held-out ID split used (i) to fit the flip-risk calibrator and (ii) to tune scalar
    thresholds for baselines (protocol below). Equivalently, $|\mathcal{D}_{\mathrm{cal}}|$ is set to
    $n_{\mathrm{cal}}=\min(5000,\lfloor |\mathcal{D}_{\mathrm{train\_pool}}|/4\rfloor)$.
    \item \textbf{Test} $\mathcal{D}_{\mathrm{test}}$ of size 5{,}000 (ID only), used for final ID evaluation.
\end{itemize}
Near-OOD and Far-OOD evaluation sets are each size 5{,}000 and are constructed from (or alongside)
$\mathcal{D}_{\mathrm{test}}$ as described in Section~\ref{subsec:datasets_preproc_shifts}.

\subsection{Models, Calibration, Suspicion, and Hyperparameters}
\label{subsec:models_calib_hparams}
We train Random Forest (RF) and Gradient Boosting (GBM) classifiers with $T{=}100$ estimators
(Table~\ref{tab:hyperparams}) for all datasets. For GBM, training is further subsampled to 10{,}000 points
when $|\mathcal{D}_{\mathrm{train}}|>10{,}000$ to keep training cost bounded.

\paragraph{Flip-risk calibration.}
To enable probabilistic early exiting, we fit a flip-risk calibrator (logistic regression) to predict
$p_{\mathrm{agree}}(t,x)=\mathbb{P}(\hat{y}_t(x)=\hat{y}_T(x))$ from prefix statistics at depths
$t\in\{1,2,4,8,16,32,64,100\}$ (Table~\ref{tab:hyperparams}).

\paragraph{OOD suspicion scoring.}
For OOD awareness, we compute an external suspicion score $u(x)$ via a KNN distance model fit on
$\mathcal{D}_{\mathrm{train}}$ (potentially using a fixed-size subsample when $|\mathcal{D}_{\mathrm{train}}|$
is large; Table~\ref{tab:hyperparams}). The stopping policy uses the calibrated agreement probability, a
minimum evaluation depth ($t_{\min}$), and suspicion thresholds that can tighten the exit rule or force
full inference when $u(x)$ is large.

\begin{table*}[t]
\centering
\caption{Hyperparameters used in all experiments. Here $\tau_{\mathrm{susp}}$ is the ``suspicious'' threshold
(used to switch between $\delta_{\mathrm{ID}}$ and $\delta_{\mathrm{susp}}$ and between
$t_{\min}^{\mathrm{ID}}$ and $t_{\min}^{\mathrm{susp}}$), and $\tau_{\mathrm{gate}}$ is the hard gate
(force full inference if $u(x)>\tau_{\mathrm{gate}}$).}
\label{tab:hyperparams}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll|l}
\toprule
\multicolumn{3}{c}{\textbf{Global hyperparameters}} \\
\midrule
RF ensemble & \texttt{n\_estimators} & 100 \\
RF ensemble & \texttt{n\_jobs} & $-1$ \\
RF ensemble & \texttt{random\_state} & 42 (scikit-learn defaults otherwise) \\
GBM ensemble & \texttt{n\_estimators} & 100 \\
GBM ensemble & \texttt{random\_state} & 42 (scikit-learn defaults otherwise) \\
GBM ensemble & train-time subsample & 10{,}000 if $|\mathcal{D}_{\mathrm{train}}|>10{,}000$ \\
Flip-risk calibrator & model & LogisticRegression (\texttt{max\_iter}=1000) \\
Flip-risk calibrator & prefix grid & $\{1,2,4,8,16,32,64,100\}$ \\
KNN suspicion $u(x)$ & neighbors $k$ & 10 \\
KNN suspicion $u(x)$ & fit subsample & 10{,}000 ID train points (if available) \\
Stopping policy & $\tau_{\mathrm{susp}}$ & 0.5 \\
Stopping policy & $t_{\min}^{\mathrm{ID}}/T$ & 0.1 \\
Stopping policy & $t_{\min}^{\mathrm{susp}}/T$ & 0.3 \\
\midrule
\multicolumn{3}{c}{\textbf{Dataset/model-specific policy hyperparameters (optimal configs)}} \\
\midrule
MNIST & RF & $\delta_{\mathrm{ID}}{=}0.10,\ \delta_{\mathrm{susp}}{=}0.01,\ \tau_{\mathrm{gate}}{=}0.70$ \\
MNIST & GBM & $\delta_{\mathrm{ID}}{=}0.10,\ \delta_{\mathrm{susp}}{=}0.05,\ \tau_{\mathrm{gate}}{=}0.70$ \\
Covertype & RF & $\delta_{\mathrm{ID}}{=}0.03,\ \delta_{\mathrm{susp}}{=}0.001,\ \tau_{\mathrm{gate}}{=}0.90$ \\
Covertype & GBM & $\delta_{\mathrm{ID}}{=}0.10,\ \delta_{\mathrm{susp}}{=}0.001,\ \tau_{\mathrm{gate}}{=}0.50$ \\
HIGGS & RF & $\delta_{\mathrm{ID}}{=}0.05,\ \delta_{\mathrm{susp}}{=}0.005,\ \tau_{\mathrm{gate}}{=}0.90$ \\
HIGGS & GBM & $\delta_{\mathrm{ID}}{=}0.10,\ \delta_{\mathrm{susp}}{=}0.005,\ \tau_{\mathrm{gate}}{=}0.90$ \\
\bottomrule
\end{tabular}
}
\end{table*}

\subsection{Baselines and ID-Only Tuning Protocol}
\label{subsec:baselines_tuning}
We compare against (i) early-exit baselines and (ii) OOD-scoring baselines.

\paragraph{Early-exit baselines.}
\begin{itemize}
    \item \textbf{Full Inference:} evaluates all $T$ components (0\% work reduction).
    \item \textbf{Uncalibrated Lazy:} exits when a confidence score exceeds a threshold $\alpha$.
    \item \textbf{Constant Threshold:} uses the calibrated flip-risk estimator but with a fixed risk
    threshold $\delta$ (no suspicion-aware adaptation).
\end{itemize}

\paragraph{OOD-scoring baselines.}
To contextualize the KNN-based suspicion score used by our method, we compare AUROC against standard
post-hoc OOD scores computed from model outputs or features: maximum softmax probability (MSP),
predictive entropy, and a Mahalanobis-distance score.

\paragraph{Baseline tuning without OOD labels.}
To ensure a fair and deployment-realistic comparison, all methods that require a scalar threshold (e.g., a confidence threshold $\alpha$ for \emph{Uncalibrated Lazy} or a risk threshold $\delta$ for \emph{Constant Threshold}) are tuned \emph{using only the in-distribution (ID) hold-out split} $D_{\mathrm{val}}$; no OOD data or OOD labels are used at any stage of tuning. For each candidate threshold, we run the corresponding early-exit policy on $D_{\mathrm{val}}$, compute (i) Work Reduction (WR) and (ii) Disagreement Rate (DR) with respect to the full-ensemble prediction $\hat{y}_T(x)$ on the \emph{same} inputs, and then select the threshold that maximizes WR subject to an ID fidelity constraint on DR (e.g., DR $\leq \delta_{\mathrm{ID}}$ or matched to the proposed method on $D_{\mathrm{val}}$). After fixing thresholds, we evaluate all methods once on the disjoint ID test split and on the Near-/Far-OOD splits. This protocol makes the comparison auditable: the early-exit operating point is determined entirely by ID fidelity to the trusted full model, and shift performance is assessed without any OOD-aware tuning.

\subsection{Metrics}
We report:
\textbf{Work Reduction (WR)} $=1-\frac{1}{N}\sum_i \frac{t_i}{T}$,
\textbf{Disagreement Rate (DR)} $=\frac{1}{N}\sum_i \mathbb{1}[\hat{y}_{t_i}\neq \hat{y}_T]$,
and \textbf{Early Exit Error Rate (EER)}, i.e., DR restricted to early-exited points ($t_i<T$).
On OOD splits we emphasize DR/EER w.r.t.\ the full model (rather than accuracy), since OOD may not share the ID label space (e.g., Covertype semantic OOD classes).

\subsection{Main Results: Efficiency and Reliability}
\label{sec:main_results}

Table~\ref{tab:main_results} presents the performance of our Risk-Aware Adaptive Inference method compared to standard baselines on In-Distribution (ID) test data.

\textbf{Efficiency.} The proposed method achieves substantial computational savings, reducing inference work by 63.0--84.1\% across the evaluated datasets. Crucially, these savings are comparable to the \textit{Constant Threshold} baseline, demonstrating that the addition of the OOD suspicion mechanism does not incur a significant efficiency penalty on ID data. In several cases (e.g., MNIST RF, HIGGS GBM), our method even achieves statistically significant improvements in work reduction ($p < 0.05$) by dynamically relaxing the risk threshold for highly confident, low-suspicion samples.

\textbf{Reliability.} While maximizing efficiency, our method maintains high fidelity to the full ensemble. The ID disagreement rate remains low (all $< 3.2\%$), ensuring that the accuracy of the adaptive system closely matches the full model. This confirms that the calibrated flip-risk estimator effectively controls the disagreement rate on in-distribution data.

\begin{table*}[t]
\centering
\caption{Main Results. Comparison of efficiency and reliability on ID test data. Work Reduction is relative to full inference. Disagreement Rate is with respect to the full model. * indicates statistically significant improvement in work reduction over Constant Threshold ($p < 0.05$).}
\label{tab:main_results}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll|ccc|ccc|ccc|ccc}
\toprule
& & \multicolumn{3}{c|}{\textbf{Proposed}} & \multicolumn{3}{c|}{\textbf{Constant Threshold}} & \multicolumn{3}{c|}{\textbf{Uncalibrated Lazy}} & \multicolumn{3}{c}{\textbf{Full Inference}} \\
Dataset & Model & Acc (\%) & Work (\%) & Disagree (\%) & Acc (\%) & Work (\%) & Disagree (\%) & Acc (\%) & Work (\%) & Disagree (\%) & Acc (\%) & Work (\%) & Disagree (\%) \\
\midrule
MNIST & RF & $95.5 \pm 0.2$ & $77.0 \pm 0.2^{*}$ & $1.0 \pm 0.1$ & -- & $87.6 \pm 0.3$ & $1.9 \pm 0.3$ & -- & $32.7 \pm 0.6$ & $0.0 \pm 0.0$ & $95.7 \pm 0.2$ & $0.0 \pm 0.0$ & $0.0 \pm 0.0$ \\
MNIST & GBM & $92.4 \pm 0.2$ & $73.3 \pm 0.4^{*}$ & $1.2 \pm 0.1$ & -- & $81.4 \pm 0.5$ & $2.0 \pm 0.2$ & -- & $36.0 \pm 0.4$ & $0.0 \pm 0.0$ & $93.3 \pm 0.3$ & $0.0 \pm 0.0$ & $0.0 \pm 0.0$ \\
\midrule
Covertype & RF & $86.2 \pm 0.5$ & $84.1 \pm 0.3^{*}$ & $2.0 \pm 0.4$ & -- & $86.0 \pm 0.2$ & $2.7 \pm 0.4$ & -- & $28.7 \pm 0.8$ & $0.0 \pm 0.0$ & $86.5 \pm 0.6$ & $0.0 \pm 0.0$ & $0.0 \pm 0.0$ \\
Covertype & GBM & $79.1 \pm 0.5$ & $83.3 \pm 0.7^{*}$ & $2.8 \pm 0.2$ & -- & $80.2 \pm 1.1$ & $1.6 \pm 0.2$ & -- & $2.3 \pm 0.2$ & $0.0 \pm 0.0$ & $80.2 \pm 0.4$ & $0.0 \pm 0.0$ & $0.0 \pm 0.0$ \\
\midrule
HIGGS & RF & $70.1 \pm 0.7$ & $63.0 \pm 0.6^{*}$ & $3.2 \pm 0.2$ & -- & $73.1 \pm 0.7$ & $5.1 \pm 0.2$ & -- & $4.9 \pm 0.4$ & $0.0 \pm 0.0$ & $70.3 \pm 0.7$ & $0.0 \pm 0.0$ & $0.0 \pm 0.0$ \\
HIGGS & GBM & $69.7 \pm 0.7$ & $66.2 \pm 1.3^{*}$ & $2.3 \pm 0.3$ & -- & $72.6 \pm 1.4$ & $2.1 \pm 0.3$ & -- & $0.1 \pm 0.0$ & $0.0 \pm 0.0$ & $70.2 \pm 0.6$ & $0.0 \pm 0.0$ & $0.0 \pm 0.0$ \\
\bottomrule
\end{tabular}
}
\end{table*}


These results establish that our method is a viable drop-in replacement for standard early-exiting strategies on ID data. However, the critical distinction lies in safety under distribution shift, which we analyze next.

\subsection{OOD Safety and Detection}
\label{sec:ood_safety}

A critical failure mode of standard early-exit mechanisms is \textit{overconfidence under distribution shift}: models may output high-confidence predictions on OOD data using only a few features, leading to premature exits with erroneous predictions. Our closed-loop policy addresses this by conditioning the stopping decision on an OOD suspicion score.

\textbf{Safety Analysis.} Figure~\ref{fig:ood_safety} illustrates the Early Exit Error Rate (EER) on Near and Far OOD splits. The \textit{Uncalibrated Lazy} baseline frequently exits early on OOD samples, resulting in high error rates among exited samples. The \textit{Constant Threshold} baseline, while calibrated for ID data, fails to adapt to shift, maintaining high work reduction even when the model's early predictions are unreliable.

In contrast, our \textit{Proposed} method dynamically adapts computational effort. For example, on MNIST GBM Far-OOD, the proposed method reduces work reduction from 57.6\% (Constant Threshold) to 2.6\%, effectively forcing deeper evaluation or full inference. This ``safety brake'' mechanism significantly reduces the early exit error rate compared to the constant threshold baseline (from 20.3\% to 5.6\%), preventing catastrophic failures on shifted data.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Fig1.eps}
    \caption{OOD Safety Analysis. Early Exit Error Rate on OOD data (lower is better). Panels: (a) Near OOD, (b) Far OOD. Bars correspond to the proposed method, constant-threshold baseline, and uncalibrated-lazy baseline.}
    \label{fig:ood_safety}
\end{figure}

\textbf{Detection Utility.} Table~\ref{tab:ood_detection} reports the AUROC of the integrated KNN-based suspicion score $u(x)$ alongside standard post-hoc OOD scores (Mahalanobis distance, predictive entropy, and maximum softmax probability). The results indicate that no single score dominates across all datasets and shift types: the KNN score provides strong separation on several near-shift settings and on MNIST Far-OOD, whereas Mahalanobis distance is more competitive on the harder tabular Far-OOD splits (e.g., Covertype and HIGGS). In RAAI, these OOD scores are not treated as a standalone robustness guarantee; rather, they serve as an inference-time \emph{gating signal} that triggers a more conservative stopping regime (tighter $\delta$ and larger $t_{\min}$) and, when $u(x)$ exceeds the hard gate, disables early exit to defer to full evaluation. This coupling is what operationalizes ``detect-then-defer'': the detector modulates compute allocation under shift, while prediction fidelity is still governed by the flip-risk criterion.

\begin{table*}[t]
\centering
\caption{OOD Detection Performance (AUROC). Comparison of the proposed KNN-based suspicion score against standard OOD detection baselines on Near and Far shifts.}
\label{tab:ood_detection}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll|c|ccc}
\toprule
Dataset & Shift & \textbf{Proposed (KNN)} & \textbf{Mahalanobis} & \textbf{Entropy} & \textbf{MSP} \\
\midrule
MNIST RF & Near & 0.965 & 0.905 & 0.955 & 0.948 \\
MNIST RF & Far & 0.994 & 0.999 & 0.998 & 0.995 \\
\midrule
MNIST GBM & Near & 0.965 & 0.905 & 0.890 & 0.885 \\
MNIST GBM & Far & 0.994 & 0.999 & 0.874 & 0.871 \\
\midrule
COVERTYPE RF & Near & 0.989 & 0.874 & 0.689 & 0.670 \\
COVERTYPE RF & Far & 0.763 & 0.789 & 0.439 & 0.417 \\
\midrule
COVERTYPE GBM & Near & 0.989 & 0.874 & 0.504 & 0.499 \\
COVERTYPE GBM & Far & 0.763 & 0.789 & 0.288 & 0.265 \\
\midrule
HIGGS RF & Near & 0.756 & 0.808 & 0.665 & 0.665 \\
HIGGS RF & Far & 0.746 & 0.820 & 0.599 & 0.599 \\
\midrule
HIGGS GBM & Near & 0.756 & 0.808 & 0.519 & 0.519 \\
HIGGS GBM & Far & 0.746 & 0.820 & 0.470 & 0.470 \\
\midrule
\bottomrule
\end{tabular}
}
\end{table*}


\subsection{Calibration Quality}\label{subsec:calibration_quality}
A key component of RAAI is the calibrated estimator $\hat{p}{\mathrm{agree}}(t,x)$, which supports a
probabilistic interpretation of the stopping threshold in Eq.~(3). We evaluate calibration of
$\hat{p}{\mathrm{agree}}(t,x)$ using (i) binned reliability diagrams and (ii) two standard scalar metrics,
Expected Calibration Error (ECE) and Maximum Calibration Error (MCE). For bins ${B_m}{m=1}^M$ over the
predicted agreement probabilities, ECE summarizes the \emph{average} deviation between empirical agreement
and predicted probability, while MCE summarizes the \emph{worst-bin} deviation:
\begin{equation}
\mathrm{ECE}=\sum{m=1}^{M}\frac{|B_m|}{n}\left|\mathrm{acc}(B_m)-\mathrm{conf}(B_m)\right|,
\qquad
\mathrm{MCE}=\max_{m\in{1,\ldots,M}}\left|\mathrm{acc}(B_m)-\mathrm{conf}(B_m)\right|,
\end{equation}
where $\mathrm{acc}(B_m)$ is the empirical agreement frequency within bin $B_m$, $\mathrm{conf}(B_m)$ is the
mean predicted agreement probability in the bin, and $n$ is the total number of evaluated points.

Table~\ref{tab:calibration} reports ECE and MCE for all dataset--model pairs. Overall, the estimator exhibits low ECE on average
(mean ECE $\approx 0.0303$), indicating that the predicted agreement probabilities are informative and
reasonably aligned with empirical agreement in aggregate. At the same time, Table~\ref{tab:calibration} shows that MCE can be
substantially larger than ECE for some pairs. This pattern is expected for binned calibration metrics:
MCE is governed by the single most discrepant bin and is therefore sensitive to bins with relatively few
samples, to the chosen binning scheme, and to local irregularities in the calibration curve. As a result,
the calibration evidence supports an \emph{approximate} probabilistic interpretation of the risk threshold
on in-distribution data, while discouraging a strict worst-case interpretation based solely on the scalar
metrics.

\begin{table}[t]
\centering
\caption{Calibration Quality. Expected Calibration Error (ECE) and Maximum Calibration Error (MCE) for the flip-risk estimator.}
\label{tab:calibration}
\begin{tabular}{llcc}
\toprule
\textbf{Dataset} & \textbf{Model} & \textbf{ECE} & \textbf{MCE} \\
\midrule
Covertype & GBM & 0.0707 & 0.7818 \\
Covertype & RF & 0.0166 & 0.6072 \\
HIGGS & GBM & 0.0287 & 0.2059 \\
HIGGS & RF & 0.0203 & 0.2984 \\
MNIST & GBM & 0.0240 & 0.3256 \\
MNIST & RF & 0.0218 & 0.7357 \\
\bottomrule
\end{tabular}
\end{table}


Figure~\ref{fig:calibration} provides complementary qualitative evidence via reliability diagrams for two representative cases
(Covertype (RF) and MNIST (GBM)). The curves track the diagonal closely in the regions with substantial
mass, consistent with the low ECE values and supporting the use of $\hat{p}_{\mathrm{agree}}(t,x)$ as a
control signal for early exit. Importantly, our closed-loop policy does not rely on calibration holding
uniformly under arbitrary shift: when the OOD suspicion score indicates potential distributional novelty,
the policy tightens the stopping requirements and can disable early exit, reducing reliance on any
in-distribution calibration assumption for suspicious inputs.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Fig2.eps}
    \caption{Reliability Diagrams. Predicted probability of agreement vs.\ empirical agreement. Panels: (a) Covertype (RF), (b) MNIST (GBM). The curves track the diagonal (perfect calibration), validating the flip-risk estimator.}
    \label{fig:calibration}
\end{figure}

\paragraph{Practical interpretation for operating-point selection.}
In deployment, $\delta$ should be treated as an interpretable tuning knob that is validated on a held-out
in-distribution split: increasing $\delta$ increases expected work reduction but may increase disagreement
with full inference, while decreasing $\delta$ improves fidelity at higher compute cost. Given the observed
gap between ECE and MCE on some tasks, we recommend selecting $\delta$ based on validation curves in the
operating region of interest (e.g., the range of $\hat{p}_{\mathrm{agree}}$ where early exits occur most
frequently), rather than relying on a single global scalar metric.

\subsection{Ablation Study}
\label{sec:ablation}

To characterize the efficiency--safety trade-off induced by the RAAI controller, we conduct an ablation
over the key policy parameters that determine (i) how aggressively the method exits early on
in-distribution (ID-like) samples and (ii) how conservatively it behaves on suspicious inputs. We vary:
(i) the ID risk tolerance $\delta_{\mathrm{ID}}$, (ii) the suspicious-sample risk tolerance
$\delta_{\mathrm{susp}}$ (with $\delta_{\mathrm{susp}} \le \delta_{\mathrm{ID}}$), and (iii) the suspicion
thresholds $\tau_{\mathrm{susp}}$ and $\tau_{\mathrm{gate}}$ that determine when the controller switches to a
more conservative regime and when it forces full inference, respectively. For each configuration, we
evaluate \textbf{ID Work Reduction (WR)} (higher is better) and \textbf{Far-OOD Disagreement Rate (DR)}
(lower is better). WR is the fraction of ensemble components skipped relative to full evaluation, and DR
is the fraction of samples whose early-exit prediction differs from the full-ensemble prediction.

\textbf{Pareto frontier.}
Figure~\ref{fig:ablation_pareto} visualizes the trade-off between ID WR and Far-OOD DR across the swept
configurations. The dashed curve indicates the Pareto frontier, i.e., the set of \emph{non-dominated}
configurations for which no other setting achieves both higher WR and lower DR simultaneously. The
operating points used for the main results (Section~\ref{sec:main_results}) are selected on or near this
frontier, indicating that the chosen controller settings provide strong efficiency gains on ID data while
maintaining conservative behavior on severe distribution shifts. To ensure readability in print, the
figure uses non-color encodings (e.g., marker shape/line style) to denote key gating parameters.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{Fig3.eps}
    \caption{Ablation study: efficiency--safety trade-off and Pareto frontier. Each point corresponds to a controller configuration obtained by varying $\delta_{\mathrm{ID}}$, $\delta_{\mathrm{susp}}$, $\tau_{\mathrm{susp}}$, and $\tau_{\mathrm{gate}}$, plotted by in-distribution Work Reduction (WR; percentage of ensemble components skipped, higher is better) versus Far-OOD Disagreement Rate (DR; fraction of samples where the early-exit prediction differs from the full-ensemble prediction, lower is better). The dashed curve indicates the Pareto frontier (non-dominated configurations). Gating settings (e.g., $\tau_{\mathrm{gate}}$) are indicated using a non-color visual encoding (e.g., marker shape or line style) to preserve interpretability in grayscale. Panels (a)--(f) correspond to MNIST RF, Covertype RF, HIGGS RF, MNIST GBM, Covertype GBM, and HIGGS GBM (row-major order).}
    \label{fig:ablation_pareto}
\end{figure*}

\textbf{Budgeted OOD disagreement trade-off and operating points.}
Figure~\ref{fig:pareto_frontier} provides a complementary view to Fig.~\ref{fig:ablation_pareto} by plotting
ID work reduction against the \emph{maximum} OOD disagreement with the full ensemble across both Near- and
Far-OOD shifts. This aggregation corresponds to a single, deployment-oriented \emph{OOD disagreement budget}
that must hold across shift severities. The vertical dashed lines in Fig.~\ref{fig:pareto_frontier} mark the
candidate budgets (2\%, 3\%, 5\%) used to select operating points. Table~\ref{tab:fig4_operating_points} then
lists, for each dataset--model pair, the configuration that maximizes ID work reduction under each budget,
including the key controller parameters $(\tau_{\mathrm{gate}}, \delta_{\mathrm{ID}}, \delta_{\mathrm{susp}})$
and the achieved Max-OOD disagreement.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{Fig4.eps}
    \caption{Budgeted Pareto frontiers for selecting OOD disagreement budgets. Each point is a controller configuration from the ablation grid, plotted by ID work reduction versus maximum OOD disagreement with the full ensemble (max over Near- and Far-OOD shifts). The solid curve traces the Pareto frontier (non-dominated configurations), and the vertical dashed lines indicate candidate OOD disagreement budgets used for selecting operating points (Table~\ref{tab:fig4_operating_points}). Panels (a)--(f) correspond to Covertype (RF), Covertype (GBM), HIGGS (RF), HIGGS (GBM), MNIST (RF), and MNIST (GBM).}
    \label{fig:pareto_frontier}
\end{figure*}

\begin{table*}[t]
\centering
\caption{Operating points for Fig.~\ref{fig:pareto_frontier}. Best ID work reduction (WR) under candidate OOD disagreement budgets. Each column reports the configuration with maximum WR subject to max OOD disagreement (max over Near/Far shifts) not exceeding the stated budget.}
\label{tab:fig4_operating_points}
\resizebox{\textwidth}{!}{
\begin{tabular}{l|ccccc|ccccc|ccccc}
\toprule
& \multicolumn{5}{c|}{$\leq$2\% OOD} & \multicolumn{5}{c|}{$\leq$3\% OOD} & \multicolumn{5}{c}{$\leq$5\% OOD} \\
Dataset & $\tau$ & $\delta_{id}$ & $\delta_{sus}$ & WR\% & Max OOD\% & $\tau$ & $\delta_{id}$ & $\delta_{sus}$ & WR\% & Max OOD\% & $\tau$ & $\delta_{id}$ & $\delta_{sus}$ & WR\% & Max OOD\% \\
\midrule
Covertype (RF) & 0.9 & 0.03 & 0.001 & 84.4 & 1.9 & 0.9 & 0.07 & 0.001 & 86.7 & 3.0 & 0.9 & 0.1 & 0.02 & 87.8 & 4.5 \\
Covertype (GBM) & 0.5 & 0.1 & 0.001 & 84.0 & 1.9 & 0.9 & 0.1 & 0.05 & 84.6 & 2.9 & 0.9 & 0.1 & 0.05 & 84.6 & 2.9 \\
HIGGS (RF) & 0.9 & 0.05 & 0.005 & 62.1 & 2.0 & 0.8 & 0.07 & 0.01 & 65.2 & 3.0 & 0.9 & 0.1 & 0.02 & 69.7 & 4.8 \\
HIGGS (GBM) & 0.9 & 0.1 & 0.005 & 66.1 & 2.0 & 0.9 & 0.1 & 0.02 & 69.2 & 3.0 & 0.9 & 0.1 & 0.05 & 71.5 & 4.4 \\
MNIST (RF) & 0.7 & 0.1 & 0.01 & 77.1 & 2.0 & 0.9 & 0.1 & 0.005 & 77.4 & 2.5 & 0.9 & 0.1 & 0.01 & 77.9 & 4.9 \\
MNIST (GBM) & 0.7 & 0.1 & 0.05 & 73.2 & 1.8 & 0.7 & 0.1 & 0.05 & 73.2 & 1.8 & 0.9 & 0.1 & 0.05 & 74.0 & 5.0 \\
\bottomrule
\end{tabular}
}
\end{table*}

\textbf{Hyperparameter roles.}
The ablation highlights distinct and interpretable roles for the controller parameters:
\begin{itemize}
    \item \textbf{ID tolerance $\delta_{\mathrm{ID}}$ (efficiency knob).} Increasing $\delta_{\mathrm{ID}}$
    relaxes the stopping condition $\hat{p}_{\mathrm{agree}}(t,x)\ge 1-\delta$ on non-suspicious inputs,
    enabling earlier exits and higher WR, but can increase disagreement with full inference when prefix
    stability is imperfect.
    \item \textbf{Suspicious tolerance $\delta_{\mathrm{susp}}$ (safety knob for intermediate suspicion).}
    Setting $\delta_{\mathrm{susp}}<\delta_{\mathrm{ID}}$ requires higher estimated agreement before exiting
    on suspicious samples, which reduces premature exits under shift at the cost of evaluating more
    ensemble components in that regime.
    \item \textbf{Suspicion threshold $\tau_{\mathrm{susp}}$ (frequency of conservative mode).} Lowering
    $\tau_{\mathrm{susp}}$ classifies more samples as suspicious, shifting operating points toward lower
    Far-OOD DR (safer) but reducing ID WR (less efficient) due to more conservative thresholds and larger
    minimum prefix requirements on a larger fraction of inputs.
    \item \textbf{Hard-gate threshold $\tau_{\mathrm{gate}}$ (escalation rate to full inference).} Lowering
    $\tau_{\mathrm{gate}}$ increases the fraction of inputs for which early exit is disabled, capping worst-case
    disagreement on severe shifts (Far-OOD) but reducing average WR even on borderline ID/near-shift samples.
\end{itemize}

\textbf{Implication for deployment.}
Taken together, these results validate the design choice to decouple (i) an \emph{efficiency mechanism}
controlled primarily by $\delta_{\mathrm{ID}}$ from (ii) a \emph{safety mechanism} driven by OOD suspicion
through $\tau_{\mathrm{susp}}$, $\tau_{\mathrm{gate}}$, and the conservative threshold $\delta_{\mathrm{susp}}$.
This separation yields a transparent operating-point selection procedure: practitioners can first set
$\tau_{\mathrm{gate}}$ to control escalation to full inference under severe novelty, then tune
$(\tau_{\mathrm{susp}},\delta_{\mathrm{susp}})$ to bound disagreement in the intermediate regime, and finally
adjust $\delta_{\mathrm{ID}}$ to recover work reduction on clearly in-distribution inputs.

\subsection{Runtime Analysis}\label{subsec:runtime}
We evaluate computational efficiency using two complementary notions: \emph{work reduction} (WR), defined
as the fraction of ensemble components skipped relative to full evaluation, and \emph{wall-clock speedup},
defined as the ratio of full-inference time to the end-to-end time of the adaptive method when both are
measured on the same test batch. Table~\ref{tab:runtime} reports WR and speedup for all dataset--model pairs.

\paragraph{Measurement protocol.}
All wall-clock measurements are end-to-end timings of the inference pipeline for a fixed test batch:
(i) \textbf{Full inference} measures the runtime of the underlying ensemble's standard forward pass
(e.g., \texttt{predict}/\texttt{predict\_proba}); (ii) \textbf{RAAI inference} measures the runtime of the
adaptive procedure including (a) OOD suspicion scoring, (b) prefix evaluation with dynamic stopping, and
(c) auxiliary computations such as margin/confidence feature extraction and calibrator evaluation.
To reduce transient effects, timings should be taken after an initial warm-up and averaged over multiple
repetitions. Because both baselines and RAAI are evaluated on the same batch, the reported speedup
summarizes net practical impact under the chosen batching regime.

\paragraph{Theoretical work reduction vs.\ observed wall-clock.}
Table~\ref{tab:runtime} highlights a critical deployment distinction between \emph{algorithmic work reduction} and realized \emph{wall-clock} performance. RAAI achieves substantial work reduction on in-distribution data (62.5--84.4\% WR), indicating that the stopping criterion frequently terminates evaluation after a small prefix of the ensemble. However, the current Python prototype yields wall-clock slowdowns (0.09$\times$--0.18$\times$ speedup, i.e., $<1$) rather than end-to-end acceleration. This discrepancy is expected when dynamic control is implemented at the Python level on top of a highly optimized ensemble backend: full inference for a batch can complete in only a few to tens of milliseconds, so fixed per-sample overhead from OOD scoring and per-step stopping checks can dominate total runtime. Accordingly, the present results should be interpreted as evidence of controllable work reduction and improved shift safety; translating these savings into wall-clock gains requires a low-overhead (compiled or vectorized) implementation of prefix accumulation, feature extraction, and stopping logic, as well as an accelerated or cheaper OOD-suspicion query.

\paragraph{Overhead sources and implications.}
Two implementation-level factors account for most of the observed slowdown. First, the KNN-based
suspicion score introduces a fixed-cost nearest-neighbor query that is distinct from tree evaluation and
does not benefit from the same low-level optimizations as the base ensemble forward pass. Second, the
dynamic stopping logic requires Python control flow and access to intermediate prefix state; this limits
vectorization and prevents the inference engine from exploiting the most optimized execution paths
available to full evaluation (e.g., tight compiled loops and cache-friendly traversal). In addition,
auxiliary computations (margin/confidence features and the calibrator evaluation) add overhead that is
incurred at each checked prefix step. These results clarify that the current experimental evidence
supports \emph{algorithmic work reduction} and improved safety under shift, while practical wall-clock
gains require an optimized implementation of the controller.

\paragraph{Engineering requirements for practical speedups.}
To translate work reduction into wall-clock improvements, RAAI should be integrated into a compiled or
vectorized inference backend. Concretely, (i) implement prefix accumulation, feature extraction, and the
stopping check in a low-level extension (C++/Cython/Numba) so that the loop over components is no longer
Python-interpreted; (ii) reduce OOD-gating cost via approximate nearest-neighbor search and/or a cheaper
distilled suspicion proxy; and (iii) batch and cache computations where possible (e.g., compute $u(x)$
once per input and avoid per-step Python object overhead). Importantly, we do not claim wall-clock
speedups in the current prototype; rather, Table~\ref{tab:runtime} quantifies both the achieved work reduction and the
runtime overhead that must be addressed for deployment.

\begin{table}[t]
\centering
\caption{Runtime Analysis. Theoretical work reduction vs. observed wall-clock speedup. Full inference time is measured in milliseconds for the test batch.}
\label{tab:runtime}
\begin{tabular}{llccc}
\toprule
\textbf{Dataset} & \textbf{Model} & \textbf{Work Red. (\%)} & \textbf{Speedup (x)} & \textbf{Full Inf. (ms)} \\
\midrule
Covertype & GBM & 83.8 & 0.09x & 12.9 \\
Covertype & RF & 84.4 & 0.18x & 24.4 \\
HIGGS & GBM & 66.2 & 0.10x & 6.5 \\
HIGGS & RF & 62.5 & 0.18x & 24.8 \\
MNIST & GBM & 73.1 & 0.13x & 72.3 \\
MNIST & RF & 77.0 & 0.11x & 36.0 \\
\bottomrule
\end{tabular}
\end{table}


\section{Discussion}\label{sec:discussion}

\subsection{Practical implications for deployed tabular inference}\label{subsec:discussion:practical}
RAAI is designed as a compute controller for tree ensembles in production settings where inference budgets are constrained but the full ensemble remains the trusted reference decision rule. The core idea is to make early exit a \emph{fidelity-controlled} procedure: instead of stopping on uncalibrated confidence, the system estimates and thresholds flip risk (the probability that the current prefix prediction would differ from the full-model prediction) and exposes this threshold as an operating parameter that can be selected to meet application-specific tolerance to deviations from full inference. To preserve reliability under distribution shift, RAAI couples flip-risk control with an OOD-aware gate that tightens stopping requirements---and can force full evaluation---for distributionally suspicious inputs, thereby targeting the dominant deployment failure mode of adaptive inference (overconfident premature exits under shift). Empirically, this design yields deployment-relevant outcomes: substantial in-distribution work reduction with low disagreement to the full ensemble, and reduced early-exit errors on near- and far-OOD regimes. At the same time, our runtime analysis highlights that these gains are primarily \emph{work} savings in the current prototype; translating them into wall-clock improvements requires low-overhead (compiled or vectorized) implementation of the stopping loop and a cheaper or accelerated OOD query, particularly when full-model inference is already highly optimized.

Empirically, the results support two deployment-relevant takeaways. First, on in-distribution data,
RAAI can achieve substantial \emph{work reduction} (fewer evaluated components) while preserving high
agreement with the full ensemble, thereby enabling throughput gains in settings where ensemble evaluation
dominates cost. Second, under distribution shift, the closed-loop gate mitigates a primary failure mode
of adaptive inference: confidently stopping early on inputs for which prefix stability is not predictive
of full-model agreement. These findings suggest that RAAI is most appropriate as a lightweight reliability
layer atop an already-trained ensemble, especially in pipelines with explicit escalation policies (e.g.,
full evaluation for suspicious inputs) and monitoring of agreement and gating rates.

\subsection{Limitations and future work}\label{subsec:discussion:limitations}
While RAAI provides an interpretable mechanism for controlling early exit via calibrated flip risk, its
current implementation and empirical scope motivate several limitations and actionable extensions.
First, the present prototype demonstrates \emph{algorithmic work reduction} but exhibits \emph{runtime
overhead} due to Python-level control flow, feature extraction, and OOD scoring; consequently, measured
wall-clock speedups are not guaranteed without low-overhead integration of the stopping logic. This is
an engineering limitation rather than a conceptual one: the stopping policy is lightweight in arithmetic
terms, but must be implemented in a compiled or vectorized manner to avoid negating savings from reduced
tree evaluation.

Second, RAAI assumes that the agreement estimator $\hat{p}_{\mathrm{agree}}(t,x)$ trained on an
in-distribution calibration set remains \emph{meaningful} at test time. Although the OOD-gated policy
reduces reliance on calibration for suspicious inputs, calibration error can still affect operating-point
selection for the in-distribution regime and for near-shift settings where gating is not triggered.

Third, the current evaluation focuses on a limited set of datasets and shift constructions. For an
Applied Intelligence audience, stronger evidence would include broader tabular suites, real drift
scenarios (temporal splits or domain transfer), and end-to-end runtime measurements under realistic batch
sizes and hardware constraints.

\paragraph{Limitations.}
\begin{itemize}
    \item \textbf{Runtime overhead in the current prototype:} Python-level control flow and OOD queries can dominate and may prevent wall-clock speedups despite work reduction.
    \item \textbf{Calibration dependence:} $\hat{p}_{\mathrm{agree}}(t,x)$ is trained on in-distribution calibration data and may be miscalibrated under shift or changing data pipelines.
    \item \textbf{OOD signal sensitivity:} KNN-distance suspicion depends on feature scaling, reference set quality, and distance metric; performance may vary across domains.
    \item \textbf{Shift coverage:} evaluated shifts do not exhaust the spectrum of real deployment drift (e.g., gradual temporal drift, acquisition shift, label shift).
    \item \textbf{Hyperparameter transferability:} chosen $(\delta_{\mathrm{ID}}, \tau_{\mathrm{gate}}, t_{\min})$ may require re-tuning across datasets and operating conditions.
    \item \textbf{Batching and systems effects:} realized gains depend on batching, memory locality, and inference engines; algorithmic savings may not translate directly to end-to-end system speedups.
\end{itemize}
While our experiments cover three benchmarks spanning image and tabular modalities, the out-of-distribution evaluations rely on controlled shift constructions (e.g., additive noise, feature permutation, and class hold-out) that isolate specific failure modes of early exit but do not fully reflect the diversity of drift encountered in deployed tabular systems, such as gradual temporal drift, training--serving skew, or feedback-driven covariate changes. In addition, the empirical scope is limited to a small set of datasets and ensemble configurations, so the reported work--reliability trade-offs should be interpreted as evidence of the method's mechanism (flip-risk control with OOD-gated escalation) rather than an exhaustive characterization across application domains. A practical next step is to extend benchmarking to larger tabular suites and to more deployment-realistic drift protocols (temporal splits, domain transfer, and streaming evaluation), and to study simple maintenance procedures (periodic recalibration of $\hat{p}_{\mathrm{agree}}$ and re-selection of gating thresholds using only in-distribution monitoring signals). These extensions would strengthen external validity while preserving the paper's central contribution: an interpretable controller that reduces evaluation work on ID inputs and allocates compute conservatively under shift.

\paragraph{Future Work.}
We view the following directions as highest impact: (1) implement the inference loop and prefix feature
extraction in a compiled backend (e.g., C++/Cython/Numba) and evaluate latency/throughput across batch
sizes; (2) reduce OOD scoring overhead using approximate neighbor search or distilled distance proxies;
(3) replace the hard gate with a smooth risk schedule $\delta(u)$ and learn it to optimize a constrained
objective (e.g., maximize work reduction subject to an OOD error bound); (4) incorporate online or
periodic recalibration of $\hat{p}_{\mathrm{agree}}$ using recent in-production data to mitigate drift;
(5) extend the framework to regression and ranking objectives and evaluate in cost-sensitive settings
with explicit SLA constraints; and (6) expand benchmarking to include real-world drift and larger-scale
tabular datasets, with ablations that isolate the contributions of calibration and gating.

\section{Conclusion}\label{sec:conclusion}
This paper introduced Risk-Aware Adaptive Inference (RAAI), a framework for early-exit inference in tree
ensembles that targets deployment-relevant reliability under distribution shift. RAAI calibrates a
flip-risk proxy---the probability that a prefix prediction disagrees with the full ensemble---and uses
this calibrated quantity as an interpretable stopping criterion. To mitigate the brittleness of
confidence-based early exit under shift, RAAI further integrates an OOD suspicion score into a closed-loop
policy that disables early exit for distributionally novel inputs. The resulting method provides a
practitioner-controlled trade-off between evaluation work and fidelity to full inference, while reducing
the incidence of unsafe premature exits when test inputs deviate from training conditions.

Although the current prototype primarily establishes work reduction and robustness benefits rather than
end-to-end speedups, the method is compatible with optimized ensemble inference backends and can be
deployed as a reliability layer without retraining the base model. Future work will focus on
implementation-level optimization, improved and cheaper OOD signals, adaptive (non-binary) risk schedules,
online recalibration under drift, and broader benchmarking on large-scale tabular workloads and real
distribution shifts.

\backmatter

\section*{Declarations}

\paragraph{Funding}
Not applicable.

\paragraph{Conflict of interest / Competing interests}
The authors declare that they have no competing interests.

\paragraph{Ethics approval and consent to participate}
Not applicable. This study uses publicly available datasets and does not involve human participants, human data, or animal subjects.

\paragraph{Consent for publication}
Not applicable.

\paragraph{Data availability}
The datasets analysed during the current study are publicly available. MNIST is available from \texttt{https://yann.lecun.com/exdb/mnist/}. The Covertype and HIGGS datasets are available from the UCI Machine Learning Repository at \texttt{https://archive.ics.uci.edu/ml/datasets/covertype} and \texttt{https://archive.ics.uci.edu/ml/datasets/HIGGS}, respectively. All derived distribution-shift variants (Near-OOD and Far-OOD constructions) are produced by deterministic preprocessing procedures described in the manuscript; the scripts to reproduce these variants are provided with the code (see Code availability).

\paragraph{Materials availability}
Not applicable.

\paragraph{Code availability}
The full implementation (including preprocessing, shift construction, and experiments) is available at \texttt{https://github.com/pz1004/risk-aware_adaptive_inference_for_tree_ensembles}.

\paragraph{Author contributions}
S.J.: conceptualization, methodology, formal analysis, visualization, and manuscript drafting.  
C.C.: conceptualization, manuscript review and editing, and supervision.

\bibliography{sn-bibliography}

\end{document}
